# SecuLite Configuration

# Target Configuration
TARGET_URL=http://host.docker.internal:8000
TARGET_PATH=/home/fr4iser/Documents/Development/FoundryCord/

# Port Configuration
ZAP_WEBUI_PORT=8080
TARGET_PORT=8000

# Scan Configuration
ZAP_SCAN_LEVEL=1  # 1=Low, 2=Medium, 3=High
SEMGREP_SEVERITY=WARNING  # INFO, WARNING, ERROR
TRIVY_SEVERITY=UNKNOWN,CRITICAL,HIGH  # UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL

# Report Configuration
REPORT_FORMAT=html  # html, json, txt
REPORT_PATH=./results

# Log Configuration
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
LOG_PATH=./logs

# Docker Configuration
DOCKER_NETWORK=bridge

# LLM/AI Configuration
# Provider: openai, gemini, huggingface, groq, mistral, anthropic
LLM_PROVIDER=openai

# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_ENDPOINT=https://api.openai.com/v1/chat/completions

# Google Gemini
GEMINI_API_KEY=
GEMINI_MODEL=gemini-pro
GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models

# HuggingFace
HF_API_KEY=
HF_MODEL=bigcode/starcoder2-15b
HF_ENDPOINT=https://api-inference.huggingface.co/models

# Groq
GROQ_API_KEY=
GROQ_MODEL=llama3-70b-8192
GROQ_ENDPOINT=https://api.groq.com/openai/v1/chat/completions

# Mistral
MISTRAL_API_KEY=
MISTRAL_MODEL=mistral-medium
MISTRAL_ENDPOINT=https://api.mistral.ai/v1/chat/completions

# Anthropic
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-opus-20240229
ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1/messages

# Set the provider and fill in the API keys for your LLM integration
